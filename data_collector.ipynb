{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b482718",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "406c30ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_data(regex_mask: str,\n",
    "                 save_to: str,\n",
    "                 new_name: str,\n",
    "                 new_columns: list = None,\n",
    "                 different_shapes: bool = False,\n",
    "                 index_label: str = None):\n",
    "    # select all filter satisfying files\n",
    "    files = glob.glob(regex_mask)\n",
    "    # create empty list to store dataframes\n",
    "    li = []\n",
    "    if different_shapes:\n",
    "        for f in files:\n",
    "            # read in np file\n",
    "            temp_df = pd.DataFrame(np.load(f))\n",
    "    \n",
    "            # append df to list\n",
    "            li.append(temp_df)\n",
    "\n",
    "        # concatenate our list of dataframes into one!\n",
    "        data = pd.concat(li, axis=0)\n",
    "    else:\n",
    "        # loop through list of files\n",
    "        for f in files:\n",
    "            # read in np file\n",
    "            temp = np.load(f)\n",
    "    \n",
    "            # append df to list\n",
    "            li.append(temp)\n",
    "        \n",
    "        # concatenate our list of np_arrays into one Pandas Frame!\n",
    "        data = pd.DataFrame(np.concatenate(li, axis=0))\n",
    "    if new_columns:\n",
    "        data.columns = new_columns\n",
    "    os.makedirs(save_to, exist_ok=True)  \n",
    "    data.to_csv(save_to + '/' + new_name + '.csv', index_label=index_label)\n",
    "    print(f\"Collected shape = {data.shape}, saved at {save_to + '/' + new_name + '.csv'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe48c4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected shape = (120000, 8), saved at ./dataset/new/labels.csv\n"
     ]
    }
   ],
   "source": [
    "labels_cols = ['Aggregated', '1', '2', '3', '4', '5', '6', '7']\n",
    "collect_data(regex_mask='./dataset/*/*.labels.npy',\n",
    "            save_to='./dataset/new',\n",
    "            new_name='labels',\n",
    "            new_columns=labels_cols,\n",
    "            different_shapes=True,\n",
    "            index_label='Position')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "871b73de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "548 features are read\n"
     ]
    }
   ],
   "source": [
    "folders = [\"comcuc\", \"cowpig1\", \"eucdov\", \"eueowl1\", \"grswoo\", \"tawowl1\"]\n",
    "feature_names = []\n",
    "with open(\"./description/feature_names.txt\", \"r\") as file:\n",
    "    feature_names = file.read().splitlines()\n",
    "print(f\"{len(feature_names)} features are read\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a17f0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected shape = (120000, 548), saved at ./dataset/new/data.csv\n"
     ]
    }
   ],
   "source": [
    "# TAKES A WHILE, COMPLETES ALL THE DATA INTO 1 ~700 MB pd DataFrame with shape (120_000, 548)\n",
    "collect_data(regex_mask='./dataset/*/*[!labels].npy',\n",
    "             save_to='./dataset/new',\n",
    "             new_name='data',\n",
    "             new_columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e24ed187",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected shape = (20000, 548), saved at ./dataset/new/comcuc.csv\n",
      "Collected shape = (20000, 8), saved at ./dataset/new/comcuc_labels.csv\n",
      "Collected shape = (20000, 548), saved at ./dataset/new/cowpig1.csv\n",
      "Collected shape = (20000, 8), saved at ./dataset/new/cowpig1_labels.csv\n",
      "Collected shape = (20000, 548), saved at ./dataset/new/eucdov.csv\n",
      "Collected shape = (20000, 8), saved at ./dataset/new/eucdov_labels.csv\n",
      "Collected shape = (20000, 548), saved at ./dataset/new/eueowl1.csv\n",
      "Collected shape = (20000, 8), saved at ./dataset/new/eueowl1_labels.csv\n",
      "Collected shape = (20000, 548), saved at ./dataset/new/grswoo.csv\n",
      "Collected shape = (20000, 8), saved at ./dataset/new/grswoo_labels.csv\n",
      "Collected shape = (20000, 548), saved at ./dataset/new/tawowl1.csv\n",
      "Collected shape = (20000, 8), saved at ./dataset/new/tawowl1_labels.csv\n"
     ]
    }
   ],
   "source": [
    "for folder in folders:\n",
    "    collect_data(regex_mask='./dataset/' + folder + '/*[!labels].npy',\n",
    "             save_to='./dataset/new',\n",
    "             new_name=folder,\n",
    "             new_columns=feature_names)\n",
    "\n",
    "    collect_data(regex_mask='./dataset/' + folder + '/*.labels.npy',\n",
    "                save_to='./dataset/new',\n",
    "                new_name=folder + '_labels',\n",
    "                new_columns=labels_cols,\n",
    "                different_shapes=True,\n",
    "                index_label='Position')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlpc",
   "language": "python",
   "name": "mlpc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}