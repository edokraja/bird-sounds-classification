{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a3ed00db-5368-48ff-a71a-5ac6b774b449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fba0e382-e887-4a59-a977-71b36e2df054",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./dataset/new/data.csv').drop(columns=\"Unnamed: 0\")\n",
    "labels = pd.read_csv('./dataset/new/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e044fb34-30c7-4fc5-9c51-c7ec3500a135",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_add = labels.iloc[:, 1]\n",
    "\n",
    "# concatenate the two DataFrames along axis=1 (i.e., add a column to df1)\n",
    "data = pd.concat([data, col_to_add], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fce052bc-3469-43de-93db-a6477e9dd08e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>zcr_std</th>\n",
       "      <th>yin_0</th>\n",
       "      <th>yin_1</th>\n",
       "      <th>yin_2</th>\n",
       "      <th>yin_3</th>\n",
       "      <th>yin_4</th>\n",
       "      <th>yin_5</th>\n",
       "      <th>yin_6</th>\n",
       "      <th>yin_7</th>\n",
       "      <th>...</th>\n",
       "      <th>cln_contrast_mean_5</th>\n",
       "      <th>cln_contrast_mean_6</th>\n",
       "      <th>cln_contrast_std_0</th>\n",
       "      <th>cln_contrast_std_1</th>\n",
       "      <th>cln_contrast_std_2</th>\n",
       "      <th>cln_contrast_std_3</th>\n",
       "      <th>cln_contrast_std_4</th>\n",
       "      <th>cln_contrast_std_5</th>\n",
       "      <th>cln_contrast_std_6</th>\n",
       "      <th>Aggregated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.166783</td>\n",
       "      <td>0.079440</td>\n",
       "      <td>490.95706</td>\n",
       "      <td>491.75300</td>\n",
       "      <td>488.98358</td>\n",
       "      <td>485.07758</td>\n",
       "      <td>469.73868</td>\n",
       "      <td>513.68710</td>\n",
       "      <td>512.65735</td>\n",
       "      <td>245.0429</td>\n",
       "      <td>...</td>\n",
       "      <td>13.885087</td>\n",
       "      <td>17.060001</td>\n",
       "      <td>6.169077</td>\n",
       "      <td>3.001384</td>\n",
       "      <td>3.211213</td>\n",
       "      <td>4.549636</td>\n",
       "      <td>3.261581</td>\n",
       "      <td>3.175519</td>\n",
       "      <td>1.371739</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.241420</td>\n",
       "      <td>0.026630</td>\n",
       "      <td>467.41357</td>\n",
       "      <td>516.48170</td>\n",
       "      <td>515.56213</td>\n",
       "      <td>514.21027</td>\n",
       "      <td>509.39246</td>\n",
       "      <td>510.75034</td>\n",
       "      <td>511.41998</td>\n",
       "      <td>511.0642</td>\n",
       "      <td>...</td>\n",
       "      <td>14.805115</td>\n",
       "      <td>17.158812</td>\n",
       "      <td>4.463205</td>\n",
       "      <td>3.956305</td>\n",
       "      <td>1.962520</td>\n",
       "      <td>2.206298</td>\n",
       "      <td>2.378360</td>\n",
       "      <td>1.921748</td>\n",
       "      <td>2.072176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.264509</td>\n",
       "      <td>0.023550</td>\n",
       "      <td>511.84506</td>\n",
       "      <td>508.17822</td>\n",
       "      <td>509.49075</td>\n",
       "      <td>509.44510</td>\n",
       "      <td>513.54913</td>\n",
       "      <td>512.35550</td>\n",
       "      <td>514.46606</td>\n",
       "      <td>515.2646</td>\n",
       "      <td>...</td>\n",
       "      <td>13.215790</td>\n",
       "      <td>16.725847</td>\n",
       "      <td>1.774137</td>\n",
       "      <td>3.766160</td>\n",
       "      <td>2.463165</td>\n",
       "      <td>1.830873</td>\n",
       "      <td>3.058117</td>\n",
       "      <td>1.740199</td>\n",
       "      <td>1.977650</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.295410</td>\n",
       "      <td>0.016382</td>\n",
       "      <td>514.25470</td>\n",
       "      <td>512.56980</td>\n",
       "      <td>4576.39400</td>\n",
       "      <td>4567.56050</td>\n",
       "      <td>4576.48800</td>\n",
       "      <td>4655.34030</td>\n",
       "      <td>4689.93850</td>\n",
       "      <td>4697.4040</td>\n",
       "      <td>...</td>\n",
       "      <td>13.193249</td>\n",
       "      <td>16.734816</td>\n",
       "      <td>3.230220</td>\n",
       "      <td>3.042296</td>\n",
       "      <td>3.633888</td>\n",
       "      <td>2.285815</td>\n",
       "      <td>2.923266</td>\n",
       "      <td>1.529872</td>\n",
       "      <td>1.633861</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.292899</td>\n",
       "      <td>0.026179</td>\n",
       "      <td>462.35953</td>\n",
       "      <td>4722.73050</td>\n",
       "      <td>4718.76900</td>\n",
       "      <td>4696.35940</td>\n",
       "      <td>4698.63870</td>\n",
       "      <td>4731.37550</td>\n",
       "      <td>4714.80960</td>\n",
       "      <td>4737.3643</td>\n",
       "      <td>...</td>\n",
       "      <td>12.740884</td>\n",
       "      <td>16.750946</td>\n",
       "      <td>3.083272</td>\n",
       "      <td>2.659685</td>\n",
       "      <td>3.981223</td>\n",
       "      <td>3.348599</td>\n",
       "      <td>2.550901</td>\n",
       "      <td>1.909587</td>\n",
       "      <td>1.636644</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 549 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   zcr_mean   zcr_std      yin_0       yin_1       yin_2       yin_3  \\\n",
       "0  0.166783  0.079440  490.95706   491.75300   488.98358   485.07758   \n",
       "1  0.241420  0.026630  467.41357   516.48170   515.56213   514.21027   \n",
       "2  0.264509  0.023550  511.84506   508.17822   509.49075   509.44510   \n",
       "3  0.295410  0.016382  514.25470   512.56980  4576.39400  4567.56050   \n",
       "4  0.292899  0.026179  462.35953  4722.73050  4718.76900  4696.35940   \n",
       "\n",
       "        yin_4       yin_5       yin_6      yin_7  ...  cln_contrast_mean_5  \\\n",
       "0   469.73868   513.68710   512.65735   245.0429  ...            13.885087   \n",
       "1   509.39246   510.75034   511.41998   511.0642  ...            14.805115   \n",
       "2   513.54913   512.35550   514.46606   515.2646  ...            13.215790   \n",
       "3  4576.48800  4655.34030  4689.93850  4697.4040  ...            13.193249   \n",
       "4  4698.63870  4731.37550  4714.80960  4737.3643  ...            12.740884   \n",
       "\n",
       "   cln_contrast_mean_6  cln_contrast_std_0  cln_contrast_std_1  \\\n",
       "0            17.060001            6.169077            3.001384   \n",
       "1            17.158812            4.463205            3.956305   \n",
       "2            16.725847            1.774137            3.766160   \n",
       "3            16.734816            3.230220            3.042296   \n",
       "4            16.750946            3.083272            2.659685   \n",
       "\n",
       "   cln_contrast_std_2  cln_contrast_std_3  cln_contrast_std_4  \\\n",
       "0            3.211213            4.549636            3.261581   \n",
       "1            1.962520            2.206298            2.378360   \n",
       "2            2.463165            1.830873            3.058117   \n",
       "3            3.633888            2.285815            2.923266   \n",
       "4            3.981223            3.348599            2.550901   \n",
       "\n",
       "   cln_contrast_std_5  cln_contrast_std_6  Aggregated  \n",
       "0            3.175519            1.371739           0  \n",
       "1            1.921748            2.072176           0  \n",
       "2            1.740199            1.977650           0  \n",
       "3            1.529872            1.633861           0  \n",
       "4            1.909587            1.636644           0  \n",
       "\n",
       "[5 rows x 549 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe2e4128-e6ba-48bd-a0f1-1a176951b840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85358\n"
     ]
    }
   ],
   "source": [
    "count_zeros = (data['Aggregated'] == 0).sum()\n",
    "\n",
    "print(count_zeros)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6ed37d-e4ba-4081-b11e-7b4e078abf8f",
   "metadata": {},
   "source": [
    "The following code is good, not a high classification but OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ba1144c-9e19-4e0e-8788-37c4293d5673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features and labels\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "# Create a KFold object to split the data into k folds\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02b872ef-71cc-4781-a725-a43b781f82fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.8425333333333335\n"
     ]
    }
   ],
   "source": [
    "# Initialize a list to store the accuracy scores for each fold\n",
    "accuracy_scores_alldata = []\n",
    "\n",
    "# Loop over each fold in the cross-validation\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "    # Split the data into training and testing sets for this fold\n",
    "    X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "    X_test, y_test = X.iloc[test_idx], y.iloc[test_idx]\n",
    "    \n",
    "    # Train a decision tree model on the training data\n",
    "    model = DecisionTreeClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Use the model to make predictions on the testing data\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate the accuracy score for this fold and append it to the list of accuracy scores\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_scores_alldata.append(accuracy)\n",
    "\n",
    "# Calculate the average accuracy score across all folds\n",
    "avg_accuracy_alldata = np.mean(accuracy_scores_alldata)\n",
    "print(\"Average accuracy:\", avg_accuracy_alldata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28435c3a-a904-45ae-8807-2cf5c7358f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8398333333333333, 0.842, 0.8444166666666667, 0.8449166666666666, 0.845125]\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a3c0fca-ae83-4449-85b7-61f0a8ab8a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15        1\n",
      "26        1\n",
      "42        1\n",
      "50        1\n",
      "51        1\n",
      "         ..\n",
      "119797    6\n",
      "119802    6\n",
      "119808    6\n",
      "119820    6\n",
      "119823    6\n",
      "Name: Aggregated, Length: 6941, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_test[y_test != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "16218d38-c448-4536-9775-8f4eb5c0ee00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15687\n"
     ]
    }
   ],
   "source": [
    "print(np.where(y_pred[y_pred == y_test] != 0, 1, 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "baa439a3-a9f3-43c4-a2da-237c9f543c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17059\n"
     ]
    }
   ],
   "source": [
    "print(np.where(y_test== 0, 1, 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ce95658a-b74c-411b-911c-1a31048a0036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.919573245794009\n"
     ]
    }
   ],
   "source": [
    "print(15687/17059)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1e1cf7-2840-4d97-ad05-6d2233cf00af",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dad6fe4e-5be3-4334-9ec7-b130d841d00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "accuracy_scores_alldataRF = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "549eca28-70a2-4874-8ed7-a8f7ec63354b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.9077500000000001\n"
     ]
    }
   ],
   "source": [
    "# Loop over each fold in the cross-validation\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "    # Split the data into training and testing sets for this fold\n",
    "    X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "    X_test, y_test = X.iloc[test_idx], y.iloc[test_idx]\n",
    "    \n",
    "    # Train a decision tree model on the training data\n",
    "    rf_classifier = RandomForestClassifier(n_estimators=100)\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Use the model to make predictions on the testing data\n",
    "    y_pred = rf_classifier.predict(X_test)\n",
    "    \n",
    "    # Calculate the accuracy score for this fold and append it to the list of accuracy scores\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_scores_alldataRF.append(accuracy)\n",
    "    \n",
    "avg_accuracy_alldataRF = np.mean(accuracy_scores_alldataRF)\n",
    "print(\"Average accuracy:\", avg_accuracy_alldataRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6576e772-542e-499e-b11d-06113833e1bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.902, 0.9015416666666667, 0.90625, 0.907625, 0.9048333333333334]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614e548a-cc83-4e63-bd41-ad3594a80c56",
   "metadata": {},
   "source": [
    "Algorithms with feature subset selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90d1ba6b-67ae-477d-9c54-8955d6f3ab82",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_subset_features=X.iloc[:, :282]\n",
    "y = data.iloc[:, -1]\n",
    "accuracy_scores_281featuresRF = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21b74e73-8f96-4ca0-a498-53f23f122f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.9039666666666666\n"
     ]
    }
   ],
   "source": [
    "for train_idx, test_idx in kf.split(X_subset_features):\n",
    "    # Split the data into training and testing sets for this fold\n",
    "    X_train, y_train = X_subset_features.iloc[train_idx], y.iloc[train_idx]\n",
    "    X_test, y_test = X_subset_features.iloc[test_idx], y.iloc[test_idx]\n",
    "    \n",
    "    # Train a decision tree model on the training data\n",
    "    rf_classifier = RandomForestClassifier(n_estimators=100)\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Use the model to make predictions on the testing data\n",
    "    y_pred = rf_classifier.predict(X_test)\n",
    "    \n",
    "    # Calculate the accuracy score for this fold and append it to the list of accuracy scores\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_scores_281featuresRF.append(accuracy)\n",
    "    \n",
    "avg_accuracy_281featuresRF = np.mean(accuracy_scores_281featuresRF)\n",
    "print(\"Average accuracy:\", avg_accuracy_281featuresRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f08ff9-8232-47af-9b6a-b03a0811c6b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adb39972-360b-40f4-ba13-eddc89d71dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores_281featuresDTC = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3efb770-80da-4e87-9d3a-5542184d6bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.8374166666666667\n"
     ]
    }
   ],
   "source": [
    "for train_idx, test_idx in kf.split(X_subset_features):\n",
    "    # Split the data into training and testing sets for this fold\n",
    "    X_train, y_train = X_subset_features.iloc[train_idx], y.iloc[train_idx]\n",
    "    X_test, y_test = X_subset_features.iloc[test_idx], y.iloc[test_idx]\n",
    "    \n",
    "    # Train a decision tree model on the training data\n",
    "    model = DecisionTreeClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Use the model to make predictions on the testing data\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate the accuracy score for this fold and append it to the list of accuracy scores\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_scores_281featuresDTC.append(accuracy)\n",
    "\n",
    "# Calculate the average accuracy score across all folds\n",
    "avg_accuracy_281featuresDTC = np.mean(accuracy_scores_281featuresDTC)\n",
    "print(\"Average accuracy:\", avg_accuracy_281featuresDTC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861c51b1-94fc-4aad-a7a5-54b3a6f2d153",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5711d54e-fc14-4028-8714-92ab0926c599",
   "metadata": {},
   "source": [
    "Feature selection with husseins code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52a8067e-90a2-4876-9225-9c916061c06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./dataset/new/data.csv').drop(columns=\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be58a318-b4a0-49c9-92ec-99de17ef8068",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = data.corr()\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "reduced_matrix = correlation_matrix.mask(mask)\n",
    "feature_redundancy = reduced_matrix.abs().sum()\n",
    "sorted_features = feature_redundancy.sort_values(ascending=False)\n",
    "\n",
    "threshold = 0.9\n",
    "selected_features = []\n",
    "for feature in sorted_features.index:\n",
    "    if not any(np.abs(correlation_matrix[feature][selected_features]) > threshold):\n",
    "        selected_features.append(feature)\n",
    "\n",
    "data = data[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "628d0a1e-607a-4e97-bd32-9a0e010b4d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_add = labels.iloc[:, 1]\n",
    "\n",
    "# concatenate the two DataFrames along axis=1 (i.e., add a column to df1)\n",
    "data = pd.concat([data, col_to_add], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d456819-f14c-4c2a-85aa-84951d268b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_melspect_std_35</th>\n",
       "      <th>raw_melspect_std_34</th>\n",
       "      <th>raw_melspect_std_33</th>\n",
       "      <th>raw_melspect_std_36</th>\n",
       "      <th>raw_melspect_std_38</th>\n",
       "      <th>raw_melspect_std_37</th>\n",
       "      <th>raw_melspect_std_39</th>\n",
       "      <th>raw_melspect_std_32</th>\n",
       "      <th>raw_melspect_std_40</th>\n",
       "      <th>raw_melspect_std_42</th>\n",
       "      <th>...</th>\n",
       "      <th>cln_contrast_mean_0</th>\n",
       "      <th>cln_contrast_mean_1</th>\n",
       "      <th>cln_contrast_std_3</th>\n",
       "      <th>cln_contrast_std_4</th>\n",
       "      <th>cln_contrast_std_5</th>\n",
       "      <th>cln_contrast_std_2</th>\n",
       "      <th>cln_contrast_std_1</th>\n",
       "      <th>cln_contrast_std_0</th>\n",
       "      <th>cln_contrast_std_6</th>\n",
       "      <th>Aggregated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.298099</td>\n",
       "      <td>0.328444</td>\n",
       "      <td>0.368817</td>\n",
       "      <td>0.370997</td>\n",
       "      <td>0.176198</td>\n",
       "      <td>0.217133</td>\n",
       "      <td>0.174130</td>\n",
       "      <td>0.293605</td>\n",
       "      <td>0.192146</td>\n",
       "      <td>0.257332</td>\n",
       "      <td>...</td>\n",
       "      <td>10.763522</td>\n",
       "      <td>5.012050</td>\n",
       "      <td>4.549636</td>\n",
       "      <td>3.261581</td>\n",
       "      <td>3.175519</td>\n",
       "      <td>3.211213</td>\n",
       "      <td>3.001384</td>\n",
       "      <td>6.169077</td>\n",
       "      <td>1.371739</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.270532</td>\n",
       "      <td>0.271270</td>\n",
       "      <td>0.357657</td>\n",
       "      <td>0.157942</td>\n",
       "      <td>0.289430</td>\n",
       "      <td>0.235276</td>\n",
       "      <td>0.288886</td>\n",
       "      <td>0.233909</td>\n",
       "      <td>0.452353</td>\n",
       "      <td>0.356668</td>\n",
       "      <td>...</td>\n",
       "      <td>7.252409</td>\n",
       "      <td>6.824798</td>\n",
       "      <td>2.206298</td>\n",
       "      <td>2.378360</td>\n",
       "      <td>1.921748</td>\n",
       "      <td>1.962520</td>\n",
       "      <td>3.956305</td>\n",
       "      <td>4.463205</td>\n",
       "      <td>2.072176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.334103</td>\n",
       "      <td>0.470067</td>\n",
       "      <td>0.465588</td>\n",
       "      <td>0.243257</td>\n",
       "      <td>0.146848</td>\n",
       "      <td>0.153000</td>\n",
       "      <td>0.183985</td>\n",
       "      <td>0.350644</td>\n",
       "      <td>0.393711</td>\n",
       "      <td>0.154153</td>\n",
       "      <td>...</td>\n",
       "      <td>4.404459</td>\n",
       "      <td>6.717711</td>\n",
       "      <td>1.830873</td>\n",
       "      <td>3.058117</td>\n",
       "      <td>1.740199</td>\n",
       "      <td>2.463165</td>\n",
       "      <td>3.766160</td>\n",
       "      <td>1.774137</td>\n",
       "      <td>1.977650</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.218709</td>\n",
       "      <td>0.352913</td>\n",
       "      <td>0.346993</td>\n",
       "      <td>0.130066</td>\n",
       "      <td>0.245454</td>\n",
       "      <td>0.246301</td>\n",
       "      <td>0.190036</td>\n",
       "      <td>0.401964</td>\n",
       "      <td>0.305665</td>\n",
       "      <td>0.408941</td>\n",
       "      <td>...</td>\n",
       "      <td>6.169155</td>\n",
       "      <td>6.823544</td>\n",
       "      <td>2.285815</td>\n",
       "      <td>2.923266</td>\n",
       "      <td>1.529872</td>\n",
       "      <td>3.633888</td>\n",
       "      <td>3.042296</td>\n",
       "      <td>3.230220</td>\n",
       "      <td>1.633861</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.170190</td>\n",
       "      <td>0.162099</td>\n",
       "      <td>0.217177</td>\n",
       "      <td>0.247123</td>\n",
       "      <td>0.154933</td>\n",
       "      <td>0.191184</td>\n",
       "      <td>0.195421</td>\n",
       "      <td>0.211458</td>\n",
       "      <td>0.282416</td>\n",
       "      <td>0.271028</td>\n",
       "      <td>...</td>\n",
       "      <td>5.772846</td>\n",
       "      <td>5.700120</td>\n",
       "      <td>3.348599</td>\n",
       "      <td>2.550901</td>\n",
       "      <td>1.909587</td>\n",
       "      <td>3.981223</td>\n",
       "      <td>2.659685</td>\n",
       "      <td>3.083272</td>\n",
       "      <td>1.636644</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 318 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   raw_melspect_std_35  raw_melspect_std_34  raw_melspect_std_33  \\\n",
       "0             0.298099             0.328444             0.368817   \n",
       "1             0.270532             0.271270             0.357657   \n",
       "2             0.334103             0.470067             0.465588   \n",
       "3             0.218709             0.352913             0.346993   \n",
       "4             0.170190             0.162099             0.217177   \n",
       "\n",
       "   raw_melspect_std_36  raw_melspect_std_38  raw_melspect_std_37  \\\n",
       "0             0.370997             0.176198             0.217133   \n",
       "1             0.157942             0.289430             0.235276   \n",
       "2             0.243257             0.146848             0.153000   \n",
       "3             0.130066             0.245454             0.246301   \n",
       "4             0.247123             0.154933             0.191184   \n",
       "\n",
       "   raw_melspect_std_39  raw_melspect_std_32  raw_melspect_std_40  \\\n",
       "0             0.174130             0.293605             0.192146   \n",
       "1             0.288886             0.233909             0.452353   \n",
       "2             0.183985             0.350644             0.393711   \n",
       "3             0.190036             0.401964             0.305665   \n",
       "4             0.195421             0.211458             0.282416   \n",
       "\n",
       "   raw_melspect_std_42  ...  cln_contrast_mean_0  cln_contrast_mean_1  \\\n",
       "0             0.257332  ...            10.763522             5.012050   \n",
       "1             0.356668  ...             7.252409             6.824798   \n",
       "2             0.154153  ...             4.404459             6.717711   \n",
       "3             0.408941  ...             6.169155             6.823544   \n",
       "4             0.271028  ...             5.772846             5.700120   \n",
       "\n",
       "   cln_contrast_std_3  cln_contrast_std_4  cln_contrast_std_5  \\\n",
       "0            4.549636            3.261581            3.175519   \n",
       "1            2.206298            2.378360            1.921748   \n",
       "2            1.830873            3.058117            1.740199   \n",
       "3            2.285815            2.923266            1.529872   \n",
       "4            3.348599            2.550901            1.909587   \n",
       "\n",
       "   cln_contrast_std_2  cln_contrast_std_1  cln_contrast_std_0  \\\n",
       "0            3.211213            3.001384            6.169077   \n",
       "1            1.962520            3.956305            4.463205   \n",
       "2            2.463165            3.766160            1.774137   \n",
       "3            3.633888            3.042296            3.230220   \n",
       "4            3.981223            2.659685            3.083272   \n",
       "\n",
       "   cln_contrast_std_6  Aggregated  \n",
       "0            1.371739           0  \n",
       "1            2.072176           0  \n",
       "2            1.977650           0  \n",
       "3            1.633861           0  \n",
       "4            1.636644           0  \n",
       "\n",
       "[5 rows x 318 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac17a10b-ed23-4c90-b955-5eb1ab367629",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "# Create a KFold object to split the data into k folds\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize a list to store the accuracy scores for each fold\n",
    "accuracy_scores_corrmatr_featureselection = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00405f7c-2584-40db-bcd8-75d57a30d458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.8400583333333334\n"
     ]
    }
   ],
   "source": [
    "# Loop over each fold in the cross-validation\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "    # Split the data into training and testing sets for this fold\n",
    "    X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "    X_test, y_test = X.iloc[test_idx], y.iloc[test_idx]\n",
    "    \n",
    "    # Train a decision tree model on the training data\n",
    "    model = DecisionTreeClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Use the model to make predictions on the testing data\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate the accuracy score for this fold and append it to the list of accuracy scores\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_scores_corrmatr_featureselection.append(accuracy)\n",
    "\n",
    "# Calculate the average accuracy score across all folds\n",
    "avg_accuracy_corrmatr_featureselection = np.mean(accuracy_scores_corrmatr_featureselection)\n",
    "print(\"Average accuracy:\", avg_accuracy_corrmatr_featureselection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806382b7-83e4-4cbd-9145-81b6966521a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d41be3e7-536a-4d73-abf9-3a9305fd8218",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores_corrmatr_featureselectionRF = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5157d51d-1a41-4029-97b6-0961fbcd2a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.9032499999999999\n"
     ]
    }
   ],
   "source": [
    "for train_idx, test_idx in kf.split(X):\n",
    "    # Split the data into training and testing sets for this fold\n",
    "    X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "    X_test, y_test = X.iloc[test_idx], y.iloc[test_idx]\n",
    "    \n",
    "    # Train a decision tree model on the training data\n",
    "    rf_classifier = RandomForestClassifier(n_estimators=100)\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Use the model to make predictions on the testing data\n",
    "    y_pred = rf_classifier.predict(X_test)\n",
    "    \n",
    "    # Calculate the accuracy score for this fold and append it to the list of accuracy scores\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_scores_corrmatr_featureselectionRF.append(accuracy)\n",
    "    \n",
    "avg_accuracy_corrmatr_featureselectionRF = np.mean(accuracy_scores_corrmatr_featureselectionRF)\n",
    "print(\"Average accuracy:\", avg_accuracy_corrmatr_featureselectionRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9127f6d2-1ed4-4612-8ce5-40ade652dacb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be61be08-56cd-4613-8694-a2fc12278461",
   "metadata": {},
   "source": [
    "Feature selection with husseins code when I drop all zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9bef821-f429-4149-9425-98539afaa201",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['Aggregated'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "895726df-9b7f-4529-8711-73968e5d588b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39691014-10b5-471b-bd98-7953ccdaf46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7845678261895563\n"
     ]
    }
   ],
   "source": [
    "# Initialize a list to store the accuracy scores for each fold\n",
    "accuracy_scores_zeroesdropped = []\n",
    "\n",
    "# Loop over each fold in the cross-validation\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "    # Split the data into training and testing sets for this fold\n",
    "    X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "    X_test, y_test = X.iloc[test_idx], y.iloc[test_idx]\n",
    "    \n",
    "    # Train a decision tree model on the training data\n",
    "    model = DecisionTreeClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Use the model to make predictions on the testing data\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate the accuracy score for this fold and append it to the list of accuracy scores\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_scores_zeroesdropped.append(accuracy)\n",
    "\n",
    "# Calculate the average accuracy score across all folds\n",
    "avg_accuracy_zeroesdropped = np.mean(accuracy_scores_zeroesdropped)\n",
    "print(\"Average accuracy:\", avg_accuracy_zeroesdropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5644fec-b8fc-4cd5-aada-c24a5e1b2a23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b116a9b-c737-4fc2-8778-55a088ca62b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.8877660897049819\n"
     ]
    }
   ],
   "source": [
    "accuracy_scores_nozeroesRF = []\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "    # Split the data into training and testing sets for this fold\n",
    "    X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "    X_test, y_test = X.iloc[test_idx], y.iloc[test_idx]\n",
    "    \n",
    "    # Train a decision tree model on the training data\n",
    "    rf_classifier = RandomForestClassifier(n_estimators=100)\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Use the model to make predictions on the testing data\n",
    "    y_pred = rf_classifier.predict(X_test)\n",
    "    \n",
    "    # Calculate the accuracy score for this fold and append it to the list of accuracy scores\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_scores_nozeroesRF.append(accuracy)\n",
    "    \n",
    "avg_accuracy_nozeroesRF = np.mean(accuracy_scores_nozeroesRF)\n",
    "print(\"Average accuracy:\", avg_accuracy_nozeroesRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e3617e-8ba6-4047-9b4d-cc75aee07331",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b25257-38e7-46c6-aad5-26028a74bacf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04319984-0e67-4de8-9c3e-ec0fcdcb2011",
   "metadata": {},
   "source": [
    "Random forest with normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4e89c944-fb98-4777-ad8d-9bed673437fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./dataset/new/data.csv').drop(columns=\"Unnamed: 0\")\n",
    "labels = pd.read_csv('./dataset/new/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0a715f-7f70-42bd-b2dd-6c7408d3c2e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "799d67fb-8025-4f2b-b821-4aa539f342ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = []\n",
    "new_labels = []\n",
    "for i in range(0,7):\n",
    "    indices = labels[labels[\"Aggregated\"] == i].sample(9000, replace=True).index.values.tolist()\n",
    "    new_data.append(data.iloc[indices])\n",
    "    new_labels.append(labels[\"Aggregated\"].iloc[indices])\n",
    "new_data = pd.concat(new_data)\n",
    "new_labels = pd.concat(new_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ef438bba-6f75-49bc-85f0-d1b80e146c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RobustScaler\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# Apply Robust Scaling to the DataFrame\n",
    "scaled_data = scaler.fit_transform(new_data)\n",
    "\n",
    "\n",
    "# Convert the scaled data back to a DataFrame\n",
    "data = pd.DataFrame(scaled_data, columns=new_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8962f1ba-92ec-4484-9219-52f3650de8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Aggregated']\n",
    "# Create the DataFrame\n",
    "labels = pd.DataFrame(new_labels, columns=columns)\n",
    "labels = labels.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ff502ac7-50ea-452b-b69d-e06e90e1eb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_add = labels.iloc[:, 0]\n",
    "\n",
    "# concatenate the two DataFrames along axis=1 (i.e., add a column to df1)\n",
    "data = pd.concat([data, col_to_add], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cd30346e-b769-4414-9e4b-be90d8bcb907",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "# Create a KFold object to split the data into k folds\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize a list to store the accuracy scores for each fold\n",
    "accuracy_scores_normalized_RF = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cc8e3e8e-eed5-478b-989d-682e846e204c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.9514285714285714\n"
     ]
    }
   ],
   "source": [
    "for train_idx, test_idx in kf.split(X):\n",
    "    # Split the data into training and testing sets for this fold\n",
    "    X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "    X_test, y_test = X.iloc[test_idx], y.iloc[test_idx]\n",
    "    \n",
    "    # Train a decision tree model on the training data\n",
    "    rf_classifier = RandomForestClassifier(n_estimators=100)\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Use the model to make predictions on the testing data\n",
    "    y_pred = rf_classifier.predict(X_test)\n",
    "    \n",
    "    # Calculate the accuracy score for this fold and append it to the list of accuracy scores\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_scores_normalized_RF.append(accuracy)\n",
    "    \n",
    "avg_accuracy_normalized_RF = np.mean(accuracy_scores_normalized_RF)\n",
    "print(\"Average accuracy:\", avg_accuracy_normalized_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b631b7-a574-4e38-ae84-247296fe274c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ae9c4838-3aea-403a-880a-0c1a58cd0f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.896079365079365\n"
     ]
    }
   ],
   "source": [
    "accuracy_scores_normalized_DTC = []\n",
    "\n",
    "# Loop over each fold in the cross-validation\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "    # Split the data into training and testing sets for this fold\n",
    "    X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "    X_test, y_test = X.iloc[test_idx], y.iloc[test_idx]\n",
    "    \n",
    "    # Train a decision tree model on the training data\n",
    "    model = DecisionTreeClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Use the model to make predictions on the testing data\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate the accuracy score for this fold and append it to the list of accuracy scores\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_scores_normalized_DTC.append(accuracy)\n",
    "\n",
    "# Calculate the average accuracy score across all folds\n",
    "avg_accuracy_normalized_DTC = np.mean(accuracy_scores_normalized_DTC)\n",
    "print(\"Average accuracy:\", avg_accuracy_normalized_DTC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4ea572-b246-4c9c-875b-a2ba27932996",
   "metadata": {},
   "source": [
    "<h2>Dataframes with Random Forest and Decision Tree Classifiers</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "050ab918-67ec-4b2b-ac65-51a922782045",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_classifiers = ['RF All Data', 'RF 281 features', 'RF with corr matrx feature selection', 'RF with feature selection no zeroes', 'RF with normalized data']\n",
    "\n",
    "# Create an empty DataFrame\n",
    "df = pd.DataFrame(columns=RF_classifiers)\n",
    "\n",
    "# Create a single row of data with the corresponding scores\n",
    "data = [avg_accuracy_alldataRF, avg_accuracy_281featuresRF, avg_accuracy_corrmatr_featureselectionRF, avg_accuracy_nozeroesRF, avg_accuracy_normalized_RF]\n",
    "\n",
    "# Add the row to the DataFrame\n",
    "df.loc[0] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cdf8e9a8-fe91-41ab-9e05-1f04693378ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RF All Data</th>\n",
       "      <th>RF 281 features</th>\n",
       "      <th>RF with corr matrx feature selection</th>\n",
       "      <th>RF with feature selection no zeroes</th>\n",
       "      <th>RF with normalized data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.90775</td>\n",
       "      <td>0.903967</td>\n",
       "      <td>0.90325</td>\n",
       "      <td>0.887766</td>\n",
       "      <td>0.951429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RF All Data  RF 281 features  RF with corr matrx feature selection  \\\n",
       "0      0.90775         0.903967                               0.90325   \n",
       "\n",
       "   RF with feature selection no zeroes  RF with normalized data  \n",
       "0                             0.887766                 0.951429  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7b3a29e3-f6b1-4ff3-949d-be2f7bf1c22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTC_classifiers = ['DTC All Data', 'DTC 281 features', 'DTC with corr matrx feature selection', 'DTC with feature selection no zeroes', 'DTC with normalized data']\n",
    "\n",
    "# Create an empty DataFrame\n",
    "accuracies_dtc = pd.DataFrame(columns=DTC_classifiers)\n",
    "\n",
    "# Create a single row of data with the corresponding scores\n",
    "data = [avg_accuracy_alldata, avg_accuracy_281featuresDTC, avg_accuracy_corrmatr_featureselection, avg_accuracy_zeroesdropped, avg_accuracy_normalized_DTC]\n",
    "\n",
    "# Add the row to the DataFrame\n",
    "accuracies_dtc.loc[0] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ba5f6bee-a5cb-49a0-9f02-620dfac512cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DTC All Data</th>\n",
       "      <th>DTC 281 features</th>\n",
       "      <th>DTC with corr matrx feature selection</th>\n",
       "      <th>DTC with feature selection no zeroes</th>\n",
       "      <th>DTC with normalized data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.842533</td>\n",
       "      <td>0.837417</td>\n",
       "      <td>0.840058</td>\n",
       "      <td>0.784568</td>\n",
       "      <td>0.896079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DTC All Data  DTC 281 features  DTC with corr matrx feature selection  \\\n",
       "0      0.842533          0.837417                               0.840058   \n",
       "\n",
       "   DTC with feature selection no zeroes  DTC with normalized data  \n",
       "0                              0.784568                  0.896079  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies_dtc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2118cf70-5635-44df-af3f-f1e245a79521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "df_transposed = df.transpose()\n",
    "accuracies_dtc_transposed = accuracies_dtc.transpose()\n",
    "\n",
    "# Create subplots with 1 row and 2 columns\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 4))\n",
    "\n",
    "# Plot the first histogram on the first subplot\n",
    "ax1 = df_transposed.plot(kind='bar', legend=False, ax=axes[0])\n",
    "ax1.set_xlabel('Classifiers')\n",
    "ax1.set_ylabel('Scores')\n",
    "ax1.set_title('Histogram of Classifier Scores - Random Forest')\n",
    "ax1.set_ylim(0.5, 1.0)\n",
    "ax1.yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1.0))\n",
    "\n",
    "\n",
    "# Plot the second histogram on the second subplot\n",
    "ax2 = accuracies_dtc_transposed.plot(kind='bar', legend=False, ax=axes[1])\n",
    "ax2.set_xlabel('Classifiers')\n",
    "ax2.set_ylabel('Scores')\n",
    "ax2.set_title('Histogram of Classifier Scores - Decision Tree Classifier')\n",
    "ax2.set_ylim(0.5, 1.0)\n",
    "ax2.yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1.0))\n",
    "\n",
    "plt.subplots_adjust(wspace=0.4)\n",
    "# Adjust the layout and spacing between subplots\n",
    "#plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa70836-ec84-4dd9-a487-addfe2e78948",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b9635c-3d8d-4d90-9124-df0a5aa1e515",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
